{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: Musical Genre Classification\n",
    "**Author: Volodymyr Savchuk**\n",
    "\n",
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'blues': 1,\n",
    "    'classical': 2,\n",
    "    'country': 3,\n",
    "    'disco': 4,\n",
    "    'hiphop': 5,\n",
    "    'jazz': 6,\n",
    "    'metal': 7,\n",
    "    'pop': 8,\n",
    "    'reggae': 9,\n",
    "    'rock': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(directory):\n",
    "    \n",
    "    labels = []\n",
    "    mel_specs = []\n",
    "    \n",
    "    for file in os.scandir(directory):\n",
    "        \n",
    "        y, sr = librosa.core.load(file)\n",
    "        \n",
    "        label = str(file).split('.')[0][11:]\n",
    "        labels.append(label)\n",
    "        \n",
    "        spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "        spect = librosa.power_to_db(spect, ref=np.max)\n",
    "        \n",
    "        if spect.shape[1] != 660:\n",
    "            spect.resize(128,660, refcheck=False)\n",
    "            \n",
    "        mel_specs.append(spect)\n",
    "        \n",
    "    X = np.array(mel_specs)\n",
    "    \n",
    "    labels = pd.Series(labels)\n",
    "    label_dict = {\n",
    "        'jazz': 1,\n",
    "        'reggae': 2,\n",
    "        'rock': 3,\n",
    "        'blues': 4,\n",
    "        'hiphop': 5,\n",
    "        'country': 6,\n",
    "        'metal': 7,\n",
    "        'classical': 8,\n",
    "        'disco': 9,\n",
    "        'pop': 10\n",
    "    }\n",
    "    y = labels.map(label_dict)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_mel_spectrogram('/Users/vozak16/Signals/musical_genre_classification/data/wavfiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract Mel Spectrograms convert to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mel_spectrogram_df(directory):\n",
    "    labels = []\n",
    "    mel_specs = []\n",
    "    \n",
    "    for file in os.scandir(directory):\n",
    "        \n",
    "        y, sr = librosa.core.load(file)\n",
    "        \n",
    "        label = str(file).split('.')[0][11:]\n",
    "        labels.append(label)\n",
    "        \n",
    "        spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "        spect = librosa.power_to_db(spect, ref=np.max)\n",
    "        \n",
    "        if spect.shape[1] != 660:\n",
    "            spect.resize(128,660, refcheck=False)\n",
    "        \n",
    "        spect = spect.flatten()\n",
    "        mel_specs.append(spect)\n",
    "        \n",
    "    mel_specs = np.array(mel_specs)\n",
    "    labels = np.array(labels).reshape(1000,1)\n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((mel_specs,labels)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs = make_mel_spectrogram_df('/Users/vozak16/Signals/musical_genre_classification/data/wavfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs = pd.read_csv('/Users/vozak16/Signals/musical_genre_classification/data/genre_mel_specs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs = mel_specs.rename(columns={'84480': 'labels'})\n",
    "mel_specs['y'] = mel_specs['labels'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs.to_csv('/Users/vozak16/Signals/musical_genre_classification/data/genre_mel_specs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function extract some numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(directory):\n",
    "\n",
    "    files = []\n",
    "    labels = []\n",
    "    zcrs = []\n",
    "    spec_centroids = []\n",
    "    spec_rolloffs = []\n",
    "    mfccs_1 = []\n",
    "    mfccs_2 = []\n",
    "    mfccs_3 = []\n",
    "    mfccs_4 = []\n",
    "    mfccs_5 = []\n",
    "    mfccs_6 = []\n",
    "    mfccs_7 = []\n",
    "    mfccs_8 = []\n",
    "    mfccs_9 = []\n",
    "    mfccs_10 = []\n",
    "    mfccs_11 = []\n",
    "    mfccs_12 = []\n",
    "    mfccs_13 = []\n",
    "    \n",
    "    for file in os.scandir(directory):\n",
    "        \n",
    "        y, sr = librosa.core.load(file)\n",
    "        \n",
    "        files.append(file)\n",
    "        \n",
    "        label = str(file).split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        zcrs.append(np.mean(zcr))\n",
    "        \n",
    "        spec_centroid = librosa.feature.spectral_centroid(y)\n",
    "        spec_centroids.append(np.mean(spec_centroid))\n",
    "        \n",
    "        spec_rolloff = librosa.feature.spectral_rolloff(y)\n",
    "        spec_rolloffs.append(np.mean(spec_rolloff))\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=512, n_mfcc=13)\n",
    "        mfcc_scaled = np.mean(mfcc.T, axis=0)\n",
    "        mfccs_1.append(mfcc_scaled[0])\n",
    "        mfccs_2.append(mfcc_scaled[1])\n",
    "        mfccs_3.append(mfcc_scaled[2])\n",
    "        mfccs_4.append(mfcc_scaled[3])\n",
    "        mfccs_5.append(mfcc_scaled[4])\n",
    "        mfccs_6.append(mfcc_scaled[5])\n",
    "        mfccs_7.append(mfcc_scaled[6])\n",
    "        mfccs_8.append(mfcc_scaled[7])\n",
    "        mfccs_9.append(mfcc_scaled[8])\n",
    "        mfccs_10.append(mfcc_scaled[9])\n",
    "        mfccs_11.append(mfcc_scaled[10])\n",
    "        mfccs_12.append(mfcc_scaled[11])\n",
    "        mfccs_13.append(mfcc_scaled[12])\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'files': files,\n",
    "        'zero_crossing_rate': zcrs,\n",
    "        'spectral_centroid': spec_centroids,\n",
    "        'spectral_rolloff': spec_rolloffs,\n",
    "        'mfcc_1': mfccs_1,\n",
    "        'mfcc_2': mfccs_2,\n",
    "        'mfcc_3': mfccs_3,\n",
    "        'mfcc_4': mfccs_4,\n",
    "        'mfcc_5': mfccs_5,\n",
    "        'mfcc_6': mfccs_6,\n",
    "        'mfcc_7': mfccs_7,\n",
    "        'mfcc_8': mfccs_8,\n",
    "        'mfcc_9': mfccs_9,\n",
    "        'mfcc_10': mfccs_10,\n",
    "        'mfcc_11': mfccs_11,\n",
    "        'mfcc_12': mfccs_12,\n",
    "        'mfcc_13': mfccs_13,\n",
    "        'labels': labels\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = extract_audio_features('/Users/vozak16/Signals/musical_genre_classification/data/wavfiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre['files'] = genre['files'].map(lambda x: x[11:-2])\n",
    "genre['labels'] = genre['labels'].map(lambda x: x[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre['y'] = genre['labels'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre.to_csv('/Users/vozak16/Signals/musical_genre_classification/data/genre_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
